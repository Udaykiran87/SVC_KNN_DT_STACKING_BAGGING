{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864f4c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, matthews_corrcoef, f1_score\n",
    "from pandas_profiling import ProfileReport\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f0ce3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human_activity_recognition_stacking(object):\n",
    "    def __init__(self,dir_path):\n",
    "        self.dir_path = dir_path\n",
    "        logging.basicConfig(filename='stacking.log', level=logging.DEBUG,\n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "        logging.info('Human_activity_recognition_stacking class object is created.')\n",
    "        \n",
    "    def prepare_datset(self):\n",
    "        \"\"\"\n",
    "        Create a final csv-'merge.csv'from the directory folder to be used as dataframe for later stage.\n",
    "        \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        None        \n",
    "        \"\"\"   \n",
    "        logging.info('Dataset preparation started from the raw data.') \n",
    "        try:\n",
    "            # assign directory\n",
    "            directory = self.dir_path\n",
    "\n",
    "            # iterate over files in\n",
    "            # that directory\n",
    "            folder_file_dict = {}\n",
    "            for filename in os.listdir(directory):\n",
    "                f = os.path.join(directory, filename)\n",
    "                # checking if it is not a file\n",
    "                if not os.path.isfile(f):\n",
    "                    file_list = [os.path.join(f, sub_filename) for sub_filename in os.listdir(f) if sub_filename != \"README.txt\"]\n",
    "                    folder_file_dict[filename] = file_list      \n",
    "            header = []\n",
    "            df_list = []\n",
    "            for key in folder_file_dict:\n",
    "                for file in folder_file_dict[key]:\n",
    "                    with open(file, \"r\", encoding=\"shift_jis\", errors=\"\", newline=\"\" ) as f:\n",
    "                        lst = csv.reader(f, delimiter=\",\")\n",
    "                        df = pd.DataFrame(lst)\n",
    "                        df.drop(df.columns[[0,4,5,6,7]], axis=1, inplace =True)\n",
    "                        df_list.append(df)\n",
    "                merged_df = pd.concat(df_list)\n",
    "                merged_df.columns = [\"frontal_axis_reading(g)\",\"vertical_axis_reading(g)\",\"lateral_axis_reading(g)\",\"activity\"]\n",
    "                merged_df.to_csv('merged.csv', index=None, header=True)\n",
    "        except Exception as e:\n",
    "            logging.error(\"{} occured while creating datasets from the raw data.\".format(str(e)))               \n",
    "            \n",
    "    def load_dataset(self):\n",
    "        \"\"\"\n",
    "        Load csv file as pandas dataframe.\n",
    "        \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        None        \n",
    "        \"\"\"\n",
    "        logging.info('Dataset is getting loaded as pandas dataframe.')\n",
    "        try:        \n",
    "            self.df = pd.read_csv(\"merged.csv\") \n",
    "            self.df.drop(['time','Unnamed: 8'], axis=1, inplace=True)\n",
    "        except FileNotFoundError:\n",
    "            logging.error(\"File not found: exception occured while loading csv as pandas dataframe.\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            logging.error(\"No data: exception occured while loading csv as pandas dataframe.\")\n",
    "        except pd.errors.ParserError:\n",
    "            logging.errornt(\"Parse error: exception occured while loading csv as pandas dataframe.\")\n",
    "        except Exception as e:\n",
    "            logging.error(\"{} occured while loading csv as pandas dataframe.\".format(str(e)))\n",
    "            \n",
    "    def create_profile_report(self,inp_df):\n",
    "        \"\"\"\n",
    "        Create pandas profile report for the input data frame.\n",
    "        \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        inp_df: Input data frame.\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        None        \n",
    "        \"\"\"    \n",
    "        logging.info('Profile reporting started for dataframe.')\n",
    "        return ProfileReport(inp_df)\n",
    "    \n",
    "    def handle_outlier(self):\n",
    "        \"\"\"\n",
    "        remove outliers for the impacted feature columns.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        None        \n",
    "        \"\"\"\n",
    "        logging.info('Outliers are getting removed.')\n",
    "        q = self.df['lateral_axis_reading(g)'].quantile(.90)\n",
    "        self.df_new = self.df[self.df['lateral_axis_reading(g)'] < q]\n",
    "        \n",
    "    def standard_scaling(self):\n",
    "        \"\"\"\n",
    "        Perform standard scaling on input dataframe.\n",
    "        \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        None        \n",
    "        \"\"\"      \n",
    "        logging.info('Standard scalling started for feature columsn.')\n",
    "        self.y = self.df_new['activity']\n",
    "        self.x = self.df_new.drop(columns=['activity'])\n",
    "        scalar = StandardScaler()\n",
    "        self.x_scaled = scalar.fit_transform(self.x)\n",
    "        self.df_new_scalar = pd.DataFrame(scalar.fit_transform(self.df_new))\n",
    "        \n",
    "    def train_test_split(self, test_size, random_state):\n",
    "        \"\"\"\n",
    "        Split data frame into train and test.\n",
    "         \n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        Train and test data for feature and predicted columns.        \n",
    "        \"\"\"\n",
    "        logging.info('train and test split for dataframe started.')\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x_scaled , self.y , test_size = test_size , random_state = random_state)\n",
    "        \n",
    "    def base_model_fit(self):\n",
    "        \n",
    "        self.knn = KNeighborsClassifier(n_neighbors=1) # Define classifier\n",
    "        self.knn.fit(self.x_train, self.y_train) # Train model           \n",
    "        \n",
    "        self.svc = SVC(C=100, gamma=1, kernel=\"rbf\")\n",
    "        self.svc.fit(self.x_train, self.y_train)       \n",
    "        \n",
    "        self.dt = DecisionTreeClassifier(criterion = 'gini', max_depth = 30, min_samples_leaf = 1, min_samples_split = 2, splitter = 'random') # Define classifier\n",
    "        self.dt.fit(self.x_train, self.y_train) # Train model\n",
    "        \n",
    "        self.rf = RandomForestClassifier(criterion = 'gini', max_depth=9, min_samples_leaf=2, n_estimators=160) # Define classifier\n",
    "        self.rf.fit(self.x_train, self.y_train) # Train model      \n",
    "        \n",
    "\n",
    "    def base_evaluate_model(self):\n",
    "        \"\"\"\n",
    "        Calculate the classification score.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        None. \n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        None. \n",
    "        \"\"\"        \n",
    "        # Make predictions\n",
    "        y_train_pred = self.knn.predict(self.x_train)\n",
    "        y_test_pred = self.knn.predict(self.x_test)\n",
    "\n",
    "        # Training set performance\n",
    "        self.knn_train_accuracy = accuracy_score(self.y_train, y_train_pred) # Calculate Accuracy\n",
    "        self.knn_train_mcc = matthews_corrcoef(self.y_train, y_train_pred) # Calculate MCC\n",
    "        self.knn_train_f1 = f1_score(self.y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "        # Test set performance\n",
    "        self.knn_test_accuracy = accuracy_score(self.y_test, y_test_pred) # Calculate Accuracy\n",
    "        self.knn_test_mcc = matthews_corrcoef(self.y_test, y_test_pred) # Calculate MCC\n",
    "        self.knn_test_f1 = f1_score(self.y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "        print('Model performance for KNN Training set')\n",
    "        print('- Accuracy: %s' % self.knn_train_accuracy)\n",
    "        print('- MCC: %s' % self.knn_train_mcc)\n",
    "        print('- F1 score: %s' % self.knn_train_f1)\n",
    "        print('----------------------------------')\n",
    "        print('Model performance for KNN Test set')\n",
    "        print('- Accuracy: %s' % self.knn_test_accuracy)\n",
    "        print('- MCC: %s' % self.knn_test_mcc)\n",
    "        print('- F1 score: %s' % self.knn_test_f1)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred = self.svc.predict(self.x_train)\n",
    "        y_test_pred = self.svc.predict(self.x_test)\n",
    "\n",
    "        # Training set performance\n",
    "        self.svc_train_accuracy = accuracy_score(self.y_train, y_train_pred) # Calculate Accuracy\n",
    "        self.svc_train_mcc = matthews_corrcoef(self.y_train, y_train_pred) # Calculate MCC\n",
    "        self.svc_train_f1 = f1_score(self.y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "        # Test set performance\n",
    "        self.svc_test_accuracy = accuracy_score(self.y_test, y_test_pred) # Calculate Accuracy\n",
    "        self.svc_test_mcc = matthews_corrcoef(self.y_test, y_test_pred) # Calculate MCC\n",
    "        self.svc_test_f1 = f1_score(self.y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "        print('Model performance for SVC Training set')\n",
    "        print('- Accuracy: %s' % self.svc_train_accuracy)\n",
    "        print('- MCC: %s' % self.svc_train_mcc)\n",
    "        print('- F1 score: %s' % self.svc_train_f1)\n",
    "        print('----------------------------------')\n",
    "        print('Model performance for SVC Test set')\n",
    "        print('- Accuracy: %s' % self.svc_test_accuracy)\n",
    "        print('- MCC: %s' % self.svc_test_mcc)\n",
    "        print('- F1 score: %s' % self.svc_test_f1)   \n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred = self.dt.predict(self.x_train)\n",
    "        y_test_pred = self.dt.predict(self.x_test)\n",
    "\n",
    "        # Training set performance\n",
    "        self.dt_train_accuracy = accuracy_score(self.y_train, y_train_pred) # Calculate Accuracy\n",
    "        self.dt_train_mcc = matthews_corrcoef(self.y_train, y_train_pred) # Calculate MCC\n",
    "        self.dt_train_f1 = f1_score(self.y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "        # Test set performance\n",
    "        self.dt_test_accuracy = accuracy_score(self.y_test, y_test_pred) # Calculate Accuracy\n",
    "        self.dt_test_mcc = matthews_corrcoef(self.y_test, y_test_pred) # Calculate MCC\n",
    "        self.dt_test_f1 = f1_score(self.y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "        print('Model performance for Decision Tree Training set')\n",
    "        print('- Accuracy: %s' % self.dt_train_accuracy)\n",
    "        print('- MCC: %s' % self.dt_train_mcc)\n",
    "        print('- F1 score: %s' % self.dt_train_f1)\n",
    "        print('----------------------------------')\n",
    "        print('Model performance for Decision Tree Test set')\n",
    "        print('- Accuracy: %s' % self.dt_test_accuracy)\n",
    "        print('- MCC: %s' % self.dt_test_mcc)\n",
    "        print('- F1 score: %s' % self.dt_test_f1) \n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred = self.rf.predict(self.x_train)\n",
    "        y_test_pred = self.rf.predict(self.x_test)\n",
    "\n",
    "        # Training set performance\n",
    "        self.rf_train_accuracy = accuracy_score(self.y_train, y_train_pred) # Calculate Accuracy\n",
    "        self.rf_train_mcc = matthews_corrcoef(self.y_train, y_train_pred) # Calculate MCC\n",
    "        self.rf_train_f1 = f1_score(self.y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "        # Test set performance\n",
    "        self.rf_test_accuracy = accuracy_score(self.y_test, y_test_pred) # Calculate Accuracy\n",
    "        self.rf_test_mcc = matthews_corrcoef(self.y_test, y_test_pred) # Calculate MCC\n",
    "        self.rf_test_f1 = f1_score(self.y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "        print('Model performance for Random Forest Training set')\n",
    "        print('- Accuracy: %s' % self.rf_train_accuracy)\n",
    "        print('- MCC: %s' % self.rf_train_mcc)\n",
    "        print('- F1 score: %s' % self.rf_train_f1)\n",
    "        print('----------------------------------')\n",
    "        print('Model performance for Random Forest Test set')\n",
    "        print('- Accuracy: %s' % self.rf_test_accuracy)\n",
    "        print('- MCC: %s' % self.rf_test_mcc)\n",
    "        print('- F1 score: %s' % self.rf_test_f1)         \n",
    "        \n",
    "    def build_stack_model(self):\n",
    "        estimator_list = [\n",
    "            ('knn',self.knn),\n",
    "            ('svm_rbf',self.svc),\n",
    "            ('dt',self.dt),\n",
    "            ('rf',self.rf)]\n",
    "        \n",
    "        # Build stack model\n",
    "        self.stack_model = StackingClassifier(\n",
    "            estimators=estimator_list, final_estimator=LogisticRegression()\n",
    "        )\n",
    "\n",
    "        # Train stacked model\n",
    "        self.stack_model.fit(self.x_train, self.y_train) \n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred = self.stack_model.predict(self.x_train)\n",
    "        y_test_pred = self.stack_model.predict(self.x_test)\n",
    "\n",
    "        # Training set model performance\n",
    "        self.stack_model_train_accuracy = accuracy_score(self.y_train, y_train_pred) # Calculate Accuracy\n",
    "        self.stack_model_train_mcc = matthews_corrcoef(self.y_train, y_train_pred) # Calculate MCC\n",
    "        self.stack_model_train_f1 = f1_score(self.y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "        # Test set model performance\n",
    "        self.stack_model_test_accuracy = accuracy_score(self.y_test, y_test_pred) # Calculate Accuracy\n",
    "        self.stack_model_test_mcc = matthews_corrcoef(self.y_test, y_test_pred) # Calculate MCC\n",
    "        self.stack_model_test_f1 = f1_score(self.y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "        print('Model performance for Stack Model Training set')\n",
    "        print('- Accuracy: %s' % self.stack_model_train_accuracy)\n",
    "        print('- MCC: %s' % self.stack_model_train_mcc)\n",
    "        print('- F1 score: %s' % self.stack_model_train_f1)\n",
    "        print('----------------------------------')\n",
    "        print('Model performance for Stack Model Test set')\n",
    "        print('- Accuracy: %s' % self.stack_model_test_accuracy)\n",
    "        print('- MCC: %s' % self.stack_model_test_mcc)\n",
    "        print('- F1 score: %s' % self.stack_model_test_f1)\n",
    "        \n",
    "    def stacking_result(self):\n",
    "        acc_train_list = {'knn':self.knn_train_accuracy,\n",
    "        'svm_rbf': self.svc_train_accuracy,\n",
    "        'dt': self.dt_train_accuracy,\n",
    "        'rf': self.rf_train_accuracy,\n",
    "        'stack': self.stack_model_train_accuracy}\n",
    "\n",
    "        mcc_train_list = {'knn':self.knn_train_mcc,\n",
    "        'svm_rbf': self.svc_train_mcc,\n",
    "        'dt': self.dt_train_mcc,\n",
    "        'rf': self.rf_train_mcc,\n",
    "        'stack': self.stack_model_train_mcc}\n",
    "\n",
    "        f1_train_list = {'knn':self.knn_train_f1,\n",
    "        'svm_rbf': self.svc_train_f1,\n",
    "        'dt': self.dt_train_f1,\n",
    "        'rf': self.rf_train_f1,\n",
    "        'stack': self.stack_model_train_f1}\n",
    "        \n",
    "        print(\"acc_train_list: \", acc_train_list)\n",
    "        print(\"mcc_train_list: \", mcc_train_list)\n",
    "        print(\"f1_train_list: \", f1_train_list)\n",
    "        \n",
    "    def predict(self,test_case):\n",
    "        \"\"\"\n",
    "        Predict the dependent feature based on the input test case.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        test_case: It is the independent variable list value. \n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        Returns the predicted feature. \n",
    "        \"\"\"               \n",
    "        logging.info('Prediction will be done for the testcase {}.'.format(test_case))\n",
    "        try:\n",
    "            return self.stack_model.predict(test_case)\n",
    "        except Exception as e:\n",
    "            logging.error(\"{} occured while predicting dependent feature.\".format(str(e)))\n",
    "            return None\n",
    "        \n",
    "    def save_stacking_model(self,file_name):\n",
    "        \"\"\"\n",
    "        Save the stacking model based on the input file name.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file_name: stacking model will be saved with this file name. \n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        None. \n",
    "        \"\"\"  \n",
    "        logging.info('Save stacking model into file: {}.'.format(file_name))\n",
    "        try:\n",
    "            pickle.dump(self.stack_model,open(file_name,'wb'))\n",
    "        except Exception as e:\n",
    "            logging.error(\"{} occured while saving stacking model.\".format(str(e)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2aa06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_obj = Human_activity_recognition_stacking('../Datasets_Healthy_Older_People')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920748bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_obj.prepare_datset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ea2450",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_obj.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "031661df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57de93cdb8f34b279200c28deca7c7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797998dd476d4f5394f78e79d60d4f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render widgets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e626850074466a92e2ce7431fcd67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342e4d9952544f018c5fb5a1f02fd884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bce18b390745cc963cba8c1f551ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inp_df = stacking_obj.df\n",
    "pf = stacking_obj.create_profile_report(inp_df)\n",
    "pf.to_widgets()\n",
    "pf.to_file(\"har_profiling.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43bcd2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_obj.handle_outlier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d742187",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_obj.standard_scaling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed8fa4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_obj.train_test_split(0.2,144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd2f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_obj.base_model_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c558001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for KNN Training set\n",
      "- Accuracy: 0.991715057143914\n",
      "- MCC: 0.9810695983862158\n",
      "- F1 score: 0.9917202798951545\n",
      "----------------------------------\n",
      "Model performance for KNN Test set\n",
      "- Accuracy: 0.9824691175382795\n",
      "- MCC: 0.9594049104448268\n",
      "- F1 score: 0.9822741623484657\n",
      "Model performance for SVC Training set\n",
      "- Accuracy: 0.9420054000073973\n",
      "- MCC: 0.8677342385213735\n",
      "- F1 score: 0.9351528048199231\n",
      "----------------------------------\n",
      "Model performance for SVC Test set\n",
      "- Accuracy: 0.9411938752866337\n",
      "- MCC: 0.8642839486455386\n",
      "- F1 score: 0.9342244931186673\n",
      "Model performance for Decision Tree Training set\n",
      "- Accuracy: 0.9937862928579354\n",
      "- MCC: 0.985793836328655\n",
      "- F1 score: 0.9937551438705274\n",
      "----------------------------------\n",
      "Model performance for Decision Tree Test set\n",
      "- Accuracy: 0.9834307271247873\n",
      "- MCC: 0.9616227001706041\n",
      "- F1 score: 0.983168345929421\n",
      "Model performance for Random Forest Training set\n",
      "- Accuracy: 0.9551170618041942\n",
      "- MCC: 0.8973757551296827\n",
      "- F1 score: 0.951498272857258\n",
      "----------------------------------\n",
      "Model performance for Random Forest Test set\n",
      "- Accuracy: 0.9516976107700273\n",
      "- MCC: 0.8881622394099415\n",
      "- F1 score: 0.9475216916009744\n"
     ]
    }
   ],
   "source": [
    "stacking_obj.base_evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d1bf63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Monalisa\\anaconda3\\envs\\machineLearning\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Stack Model Training set\n",
      "- Accuracy: 0.9934904020416466\n",
      "- MCC: 0.9851159000644004\n",
      "- F1 score: 0.9934617602359758\n",
      "----------------------------------\n",
      "Model performance for Stack Model Test set\n",
      "- Accuracy: 0.9838745469339448\n",
      "- MCC: 0.9626287075766038\n",
      "- F1 score: 0.983582261970428\n"
     ]
    }
   ],
   "source": [
    "stacking_obj.build_stack_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6077ac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train_list:  {'knn': 0.991715057143914, 'svm_rbf': 0.9420054000073973, 'dt': 0.9937862928579354, 'rf': 0.9551170618041942, 'stack': 0.9934904020416466}\n",
      "mcc_train_list:  {'knn': 0.9810695983862158, 'svm_rbf': 0.8677342385213735, 'dt': 0.985793836328655, 'rf': 0.8973757551296827, 'stack': 0.9851159000644004}\n",
      "f1_train_list:  {'knn': 0.9917202798951545, 'svm_rbf': 0.9351528048199231, 'dt': 0.9937551438705274, 'rf': 0.951498272857258, 'stack': 0.9934617602359758}\n"
     ]
    }
   ],
   "source": [
    "stacking_obj.stacking_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92c4818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.61766687,  1.38984107,  0.80791472])]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "testcase = [stacking_obj.x_test[700]]\n",
    "print(testcase)\n",
    "print(stacking_obj.predict(testcase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b8bd1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_obj.save_stacking_model('stack_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b09a19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
